{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2748073c",
   "metadata": {},
   "source": [
    "#### sklearn.model_selection.KFold\n",
    "* class sklearn.model_selection.KFold(n_splits=5, *, shuffle=False, random_state=None)\n",
    "- 매개변수 : n_splits=5, *, shuffle=False, random_state=None\n",
    "- n_splits=5 : 기본 5개로 나눔\n",
    "- * : 2개 이상\n",
    "- shuffle=False : random 뽐는 것\n",
    "- random_state=None : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a509a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=5, random_state=None, shuffle=False)\n",
      "붓꽃 데이터 세트 크기:  150\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "features = iris.data\n",
    "label = iris.target\n",
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "#5개의 폴드 세트로 분리하는 \n",
    "kfold = KFold(n_splits=5)\n",
    "print(kfold)\n",
    "cv_accuracy = []\n",
    "print('붓꽃 데이터 세트 크기: ' , features.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d055a6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object _BaseKFold.split at 0x12dd53520>\n"
     ]
    }
   ],
   "source": [
    "print(kfold.split(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "423d753d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,\n",
      "        43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "        56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,\n",
      "        69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,\n",
      "        82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,\n",
      "        95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107,\n",
      "       108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
      "       121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133,\n",
      "       134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,\n",
      "       147, 148, 149]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]))\n",
      "(array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  60,  61,  62,  63,  64,  65,  66,  67,  68,\n",
      "        69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,\n",
      "        82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,\n",
      "        95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107,\n",
      "       108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
      "       121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133,\n",
      "       134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,\n",
      "       147, 148, 149]), array([30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46,\n",
      "       47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]))\n",
      "(array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "        52,  53,  54,  55,  56,  57,  58,  59,  90,  91,  92,  93,  94,\n",
      "        95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107,\n",
      "       108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
      "       121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133,\n",
      "       134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,\n",
      "       147, 148, 149]), array([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76,\n",
      "       77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89]))\n",
      "(array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
      "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89, 120,\n",
      "       121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133,\n",
      "       134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,\n",
      "       147, 148, 149]), array([ 90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102,\n",
      "       103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115,\n",
      "       116, 117, 118, 119]))\n",
      "(array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
      "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
      "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
      "       117, 118, 119]), array([120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132,\n",
      "       133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,\n",
      "       146, 147, 148, 149]))\n"
     ]
    }
   ],
   "source": [
    "for i in kfold.split(features):\n",
    "    print(i) # 인덱스 번호 프린트 됨. feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6efe722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[[ 30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,\n",
    "        43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
    "        56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,\n",
    "        69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,\n",
    "        82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,\n",
    "        95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107,\n",
    "       108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
    "       121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133,\n",
    "       134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,\n",
    "       147, 148, 149]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f48e3c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#1 교차 검증 정확도 :0.0, 학습 데이터 크기: 100, 검증 데이터 크기 : 50\n",
      "#1 검증 세트 인덱스 : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "\n",
      "#2 교차 검증 정확도 :0.0, 학습 데이터 크기: 100, 검증 데이터 크기 : 50\n",
      "#2 검증 세트 인덱스 : [50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73\n",
      " 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97\n",
      " 98 99]\n",
      "\n",
      "#3 교차 검증 정확도 :0.0, 학습 데이터 크기: 100, 검증 데이터 크기 : 50\n",
      "#3 검증 세트 인덱스 : [100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      " 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135\n",
      " 136 137 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "₩n## 평균 검증 정확도 : 0.0\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=3)\n",
    "cv_accuracy = []\n",
    "n_iter = 0\n",
    "\n",
    "# kfold객체의 split() 호출하면 폴드 별 학습용, 검증용 테스트의 로우 인덱스를 array로 변환\n",
    "for train_index, test_index in kfold.split(features):\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "    #학습 및 예측\n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    pred = dt_clf.predict(X_test)\n",
    "    n_iter +=1\n",
    "    #반복 시 마다 정확도 측정\n",
    "    accuracy = np.round(accuracy_score(y_test,pred),4 )\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "    print(f\"\\n#{n_iter} 교차 검증 정확도 :{accuracy}, 학습 데이터 크기: {train_size}, 검증 데이터 크기 : {test_size}\")\n",
    "    print(f\"#{n_iter} 검증 세트 인덱스 : {test_index}\")\n",
    "    cv_accuracy.append(accuracy)\n",
    "    \n",
    "# 개별 iteration별 정확도를 합하여 평균 정확도 계산\n",
    "print('₩n## 평균 검증 정확도 :',np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ceadb5",
   "metadata": {},
   "source": [
    "* classification에 있어서 lable 주어져 있을 떄 한쪽으로 치워칠 가능성 있음\n",
    "- 레이블 보고 참고해서 균형있게 가지고 와야함 (stratified하게 가져와야함)\n",
    "- stratified 사용해야함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8422729",
   "metadata": {},
   "source": [
    "#### sklearn.model_selection.StratifiedKFold\n",
    "* class sklearn.model_selection.StratifiedKFold(n_splits=5, *, shuffle=False, random_state=None)\n",
    "- 균형있게 뽑기 위해 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1462dce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 교차검증 1 \n",
      "label\n",
      "2    34\n",
      "0    33\n",
      "1    33\n",
      "Name: count, dtype: int64\n",
      "## 교차검증 2 \n",
      "label\n",
      "1    34\n",
      "0    33\n",
      "2    33\n",
      "Name: count, dtype: int64\n",
      "## 교차검증 3 \n",
      "label\n",
      "0    34\n",
      "1    33\n",
      "2    33\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pandas as pd\n",
    "\n",
    "iris_df = pd.DataFrame(features, columns=iris.feature_names)\n",
    "iris_df['label'] = iris.target\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "\n",
    "cv_accuracy = []\n",
    "\n",
    "n_iter = 0\n",
    "for train_index, test_index in skf.split(features , label):\n",
    "    # print(test_index)\n",
    "    n_iter +=1\n",
    "    label_train = iris_df['label'].iloc[train_index]\n",
    "    label_test = iris_df['label'].iloc[test_index]\n",
    "    print(f'## 교차검증 {n_iter} ')\n",
    "    print(label_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "76b5aa01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#1 교차 검증 정확도 :0.98, 학습 데이터 크기: 100, 검증 데이터 크기 : 50\n",
      "#1 검증 세트 인덱스 : [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  50\n",
      "  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115]\n",
      "\n",
      "#2 교차 검증 정확도 :0.94, 학습 데이터 크기: 100, 검증 데이터 크기 : 50\n",
      "#2 검증 세트 인덱스 : [ 17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  67\n",
      "  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82 116 117 118\n",
      " 119 120 121 122 123 124 125 126 127 128 129 130 131 132]\n",
      "\n",
      "#3 교차 검증 정확도 :0.98, 학습 데이터 크기: 100, 검증 데이터 크기 : 50\n",
      "#3 검증 세트 인덱스 : [ 34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  83  84\n",
      "  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 133 134 135\n",
      " 136 137 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "₩n## 평균 검증 정확도 : 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=3)\n",
    "cv_accuracy = []\n",
    "n_iter = 0\n",
    "\n",
    "# kfold객체의 split() 호출하면 폴드 별 학습용, 검증용 테스트의 로우 인덱스를 array로 변환\n",
    "for train_index, test_index in skf.split(features, label):\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "    #학습 및 예측\n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    pred = dt_clf.predict(X_test)\n",
    "    n_iter +=1\n",
    "    #반복 시 마다 정확도 측정\n",
    "    accuracy = np.round(accuracy_score(y_test,pred),4 )\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "    print(f\"\\n#{n_iter} 교차 검증 정확도 :{accuracy}, 학습 데이터 크기: {train_size}, 검증 데이터 크기 : {test_size}\")\n",
    "    print(f\"#{n_iter} 검증 세트 인덱스 : {test_index}\")\n",
    "    cv_accuracy.append(accuracy)\n",
    "    \n",
    "# 개별 iteration별 정확도를 합하여 평균 정확도 계산\n",
    "print('₩n## 평균 검증 정확도 :',np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a6ac961e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#1 교차 검증 정확도 :0.9667, 학습 데이터 크기: 120, 검증 데이터 크기 : 30\n",
      "#1 검증 세트 인덱스 : [  0   1   2   3   4   5   6   7   8   9  50  51  52  53  54  55  56  57\n",
      "  58  59 100 101 102 103 104 105 106 107 108 109]\n",
      "\n",
      "#2 교차 검증 정확도 :0.9667, 학습 데이터 크기: 120, 검증 데이터 크기 : 30\n",
      "#2 검증 세트 인덱스 : [ 10  11  12  13  14  15  16  17  18  19  60  61  62  63  64  65  66  67\n",
      "  68  69 110 111 112 113 114 115 116 117 118 119]\n",
      "\n",
      "#3 교차 검증 정확도 :0.9, 학습 데이터 크기: 120, 검증 데이터 크기 : 30\n",
      "#3 검증 세트 인덱스 : [ 20  21  22  23  24  25  26  27  28  29  70  71  72  73  74  75  76  77\n",
      "  78  79 120 121 122 123 124 125 126 127 128 129]\n",
      "\n",
      "#4 교차 검증 정확도 :0.9667, 학습 데이터 크기: 120, 검증 데이터 크기 : 30\n",
      "#4 검증 세트 인덱스 : [ 30  31  32  33  34  35  36  37  38  39  80  81  82  83  84  85  86  87\n",
      "  88  89 130 131 132 133 134 135 136 137 138 139]\n",
      "\n",
      "#5 교차 검증 정확도 :1.0, 학습 데이터 크기: 120, 검증 데이터 크기 : 30\n",
      "#5 검증 세트 인덱스 : [ 40  41  42  43  44  45  46  47  48  49  90  91  92  93  94  95  96  97\n",
      "  98  99 140 141 142 143 144 145 146 147 148 149]\n",
      "₩n## 평균 검증 정확도 : 0.9600200000000001\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5)\n",
    "cv_accuracy = []\n",
    "n_iter = 0\n",
    "\n",
    "# kfold객체의 split() 호출하면 폴드 별 학습용, 검증용 테스트의 로우 인덱스를 array로 변환\n",
    "for train_index, test_index in skf.split(features, label):\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "    #학습 및 예측\n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    pred = dt_clf.predict(X_test)\n",
    "    n_iter +=1\n",
    "    #반복 시 마다 정확도 측정\n",
    "    accuracy = np.round(accuracy_score(y_test,pred),4 )\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "    print(f\"\\n#{n_iter} 교차 검증 정확도 :{accuracy}, 학습 데이터 크기: {train_size}, 검증 데이터 크기 : {test_size}\")\n",
    "    print(f\"#{n_iter} 검증 세트 인덱스 : {test_index}\")\n",
    "    cv_accuracy.append(accuracy)\n",
    "    \n",
    "# 개별 iteration별 정확도를 합하여 평균 정확도 계산\n",
    "print('₩n## 평균 검증 정확도 :',np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314be651",
   "metadata": {},
   "source": [
    "#### sklearn.model_selection.cross_val_score\n",
    "* sklearn.model_selection.cross_val_score(estimator -> 알고리즘이름 적어줌, X, y=None, *, groups=None, scoring=None, cv=None, n_jobs=None, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', error_score=nan)\n",
    "\n",
    "\n",
    "y=None : straitfied 하기 위해서 \n",
    "cv = 교차검증할 때 써먹음. 몇 fold로 나눌 것인가? \n",
    "verbose : 찍어보고 싶을때\n",
    "\n",
    "* parameters : \n",
    "\n",
    "    estimatorestimator object implementing ‘fit’\n",
    "    The object to use to fit the data.\n",
    "\n",
    "\n",
    "    X :array-like of shape (n_samples, n_features)\n",
    "    The data to fit. Can be for example a list, or an array.\n",
    "\n",
    "    y : array-like of shape (n_samples,) or (n_samples, n_outputs), default=None\n",
    "    The target variable to try to predict in the case of supervised learning.\n",
    "\n",
    "    groups : array-like of shape (n_samples,), default=None\n",
    "    Group labels for the samples used while splitting the dataset into train/test set. Only used in conjunction with a “Group” cv instance (e.g., GroupKFold).\n",
    "\n",
    "    scoring : str or callable, default=None\n",
    "    A str (see model evaluation documentation) or a scorer callable object / function with signature scorer(estimator, X, y) which should return only a single value.\n",
    "\n",
    "    Similar to cross_validate but only a single metric is permitted.\n",
    "\n",
    "    If None, the estimator’s default scorer (if available) is used.\n",
    "\n",
    "    cvint, cross-validation generator or an iterable, default=None\n",
    "    Determines the cross-validation splitting strategy. Possible inputs for cv are:\n",
    "\n",
    "    None, to use the default 5-fold cross validation,\n",
    "    int, to specify the number of folds in a (Stratified)KFold,\n",
    "    CV splitter,\n",
    "    An iterable that generates (train, test) splits as arrays of indices.\n",
    "    For int/None inputs, if the estimator is a classifier and y is either binary or multiclass, StratifiedKFold is used. In all other cases, KFold is used. These splitters are instantiated with shuffle=False so the splits will be the same across calls.\n",
    "\n",
    "    Refer User Guide for the various cross-validation strategies that can be used here.\n",
    "\n",
    "    Changed in version 0.22: cv default value if None changed from 3-fold to 5-fold.\n",
    "    n_jobsint, default=None\n",
    "    Number of jobs to run in parallel. Training the estimator and computing the score are parallelized over the cross-validation splits. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.\n",
    "\n",
    "    verboseint, default=0\n",
    "    The verbosity level.\n",
    "\n",
    "    fit_paramsdict, default=None\n",
    "    Parameters to pass to the fit method of the estimator.\n",
    "\n",
    "    pre_dispatchint or str, default=’2*n_jobs’\n",
    "    Controls the number of jobs that get dispatched during parallel execution. Reducing this number can be useful to avoid an explosion of memory consumption when more jobs get dispatched than CPUs can process. This parameter can be:\n",
    "\n",
    "    None, in which case all the jobs are immediately created and spawned. Use this for lightweight and fast-running jobs, to avoid delays due to on-demand spawning of the jobs\n",
    "    An int, giving the exact number of total jobs that are spawned\n",
    "    A str, giving an expression as a function of n_jobs, as in ‘2*n_jobs’\n",
    "    error_score‘raise’ or numeric, default=np.nan\n",
    "    Value to assign to the score if an error occurs in estimator fitting. If set to ‘raise’, the error is raised. If a numeric value is given, FitFailedWarning is raised.\n",
    "\n",
    "    New in version 0.20.\n",
    "    \n",
    "    ex) print(cross_val_score(lasso, X, y, cv=3)) -> 3폴드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e648593",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
